import PyPDF2  # Bibliothèque utilisée pour lire et manipuler des fichiers PDF.
import re  # Module pour utiliser des expressions régulières, permettant de rechercher des motifs spécifiques dans du texte.
import os  # Module pour interagir avec le système de fichiers (accéder à des dossiers, fichiers, etc.).
import pandas as pd  # Bibliothèque utilisée pour la manipulation de données sous forme de tableaux (DataFrames).

# Fonction pour nettoyer le texte récupéré des fichiers PDF
def clean_text(text):
    # Remplacer plusieurs espaces ou sauts de ligne consécutifs par un seul espace
    cleaned_text = re.sub(r'\s+', ' ', text)
    # Supprimer les sauts de ligne (\n, \r) et les espaces inutiles au début et à la fin du texte
    cleaned_text = cleaned_text.replace('\n', ' ').replace('\r', ' ').strip()
    return cleaned_text  # Retourner le texte nettoyé

# Fonction pour rechercher des motifs avec deux méthodes : finditer (plusieurs résultats) et search (premier résultat)
def search_and_finditer(patterns, text, groups):
    match = None  # Initialiser la variable de correspondance à None
    # Tenter de trouver des correspondances avec re.finditer (qui retourne toutes les correspondances)
    for pattern in patterns:
        matches = list(re.finditer(pattern, text))  # Trouver toutes les correspondances avec le motif
        if matches:
            # Si des correspondances sont trouvées, retourner les groupes (informations) du dernier match
            return matches[-1].groups()[:groups]  
    # Si finditer ne trouve rien, utiliser re.search (qui retourne seulement la première correspondance)
    for pattern in patterns:
        match = re.search(pattern, text)  # Rechercher la première correspondance
        if match:
            return match.groups()[:groups]  # Retourner les informations trouvées
    return [None] * groups  # Si aucune correspondance n'est trouvée, retourner une liste de None

# Fonction pour extraire des informations spécifiques à partir du texte
def extract_information(text):
    # Nettoyer le texte avant l'extraction pour éviter les espaces inutiles
    text = clean_text(text)

    data = {}  # Dictionnaire vide pour stocker les informations extraites

    # Liste de motifs regex pour extraire les informations du collecteur (nom, prénom, e-mail, mobile)
    collector_patterns = [
        r"COLLECTEUR\s+Nom:\s*(\w+)\s+Prénom:\s*(\w+)\s+E-Mail:\s*([\w\.-]+@[\w\.-]+)\s+Mobile:\s*(\d+)",
        # D'autres motifs similaires sont listés ici pour s'adapter aux variations dans le texte
    ]
    
    # Extraction des informations du collecteur à partir du texte
    collector_info = search_and_finditer(collector_patterns, text, 4)
    # Stocker les informations extraites dans le dictionnaire 'data'
    data['NOM_COLLECTEUR'], data['PRENOM_COLLECTEUR'], data['EMAIL_COLLECTEUR'], data['MOBILE_COLLECTEUR'] = collector_info
    
    # Liste de motifs regex pour extraire les informations du signataire 1
    signatory1_patterns = [
        r"SIGNATAIRE1\s+Nom:\s*([\w\s\-]+)\s+Prénom:\s*([\w\s\-]+)\s+E-Mail:\s*([\w\.-]+@[\w\.-]+)\s+Mobile:\s*(\d+)",
        # D'autres motifs similaires pour couvrir différentes variantes de texte
    ]
    
    # Extraction des informations du signataire 1 à partir du texte
    signatory1_info = search_and_finditer(signatory1_patterns, text, 4)
    # Stocker les informations extraites dans le dictionnaire 'data'
    data['NOM_SIGNATAIRE1'], data['PRENOM_SIGNATAIRE1'], data['EMAIL_SIGNATAIRE1'], data['MOBILE_SIGNATAIRE1'] = signatory1_info

    # Liste de motifs regex pour extraire la date de création du document
    date_patterns = [
        r"DÉTAILS\s+(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})",
        # D'autres motifs similaires pour couvrir différentes variantes
    ]
    
    # Extraction de la date de création à partir du texte
    date_creation = search_and_finditer(date_patterns, text, 1)
    # Stocker la date dans le dictionnaire 'data'
    data['DATE_CREATION'] = date_creation[0]
    
    # Liste de motifs regex pour extraire les informations du créateur du document
    creator_patterns = [
        r"Création de la collecte par\s*(\w+)\s*(\w+)\s*<\s*([\w\.-]+@[\w\.-]+)\s*>",
        # D'autres motifs similaires
    ]
    
    # Extraction des informations du créateur à partir du texte
    creator_info = search_and_finditer(creator_patterns, text, 3)
    # Stocker les informations extraites dans le dictionnaire 'data'
    data['PRENOM_CREATEUR'], data['NOM_CREATEUR'], data['EMAIL_CREATEUR'] = creator_info

    # Liste de motifs regex pour extraire la date de connexion et l'adresse IP
    connexion_patterns = [
        r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*Adresse IP\s*:\s*([\d\.]+)",
        # D'autres motifs similaires
    ]
    
    # Extraction des informations de connexion (date et IP) à partir du texte
    connexion_info = search_and_finditer(connexion_patterns, text, 2)
    # Stocker les informations dans le dictionnaire 'data'
    data['IP_SIGNATAIRE'], data['DATE_CONNEXION'] = connexion_info

    # Liste de motifs regex pour extraire les informations d'authentification (date et numéro de mobile)
    auth_patterns = [
        r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*Authentification du signataire : envoi de l'OTP à <(\d+)>",
        # D'autres motifs similaires
    ]
    
    # Extraction des informations d'authentification à partir du texte
    auth_info = search_and_finditer(auth_patterns, text, 2)
    # Stocker les informations extraites dans le dictionnaire 'data'
    data['DATE_AUTHENTIFICATION'], data['MOBILE_AUTHENTIFICATION'] = auth_info

    # Liste de motifs regex pour extraire la date d'approbation
    approval_patterns = [
        r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*Le signataire a approuvé les conditions",
        # D'autres motifs similaires
    ]
    
    # Extraction de la date d'approbation à partir du texte
    approval_info = search_and_finditer(approval_patterns, text, 1)
    # Stocker la date dans le dictionnaire 'data'
    data['DATE_APPROBATION'] = approval_info[0] if approval_info[0] else None

    # Retourner le dictionnaire contenant toutes les informations extraites
    return data

# Chemin du dossier contenant les fichiers PDF à analyser
folder_path = 'M:/Surete/DONNEES_CONTRATS/ESIGNATURE/PDF'  # Chemin du dossier des fichiers PDF

# Liste pour stocker les informations extraites de chaque fichier PDF
all_data = []

# Parcourir chaque fichier PDF dans le dossier
for filename in os.listdir(folder_path):
    if filename.endswith('.pdf'):  # Vérifier si le fichier a l'extension .pdf
        pdf_path = os.path.join(folder_path, filename)  # Obtenir le chemin complet du fichier PDF
        with open(pdf_path, 'rb') as pdf_file:  # Ouvrir le fichier en mode binaire
            reader = PyPDF2.PdfReader(pdf_file)  # Lire le fichier PDF
            text = ''  # Variable pour stocker le texte extrait du PDF
            for page in reader.pages:  # Parcourir chaque page du PDF
                text += page.extract_text()  # Extraire le texte de la page et l'ajouter à la variable 'text'

        # Extraire les informations du texte du PDF
        extracted_data = extract_information(text)
        # Ajouter les données extraites à la liste 'all_data'
        all_data.append(extracted_data)

# Convertir la liste des données extraites en un DataFrame pandas
df = pd.DataFrame(all_data)

# Chemin pour enregistrer les données extraites dans un fichier CSV
output_csv_path = 'M:/Surete/DONNEES_CONTRATS/ESIGNATURE/XT_TEMP.csv'

# Enregistrer le DataFrame dans un fichier CSV
df.to_csv(output_csv_path, index=False)  # index=False pour ne pas inclure les index pandas
print(f"Les données extraites ont été enregistrées dans '{output_csv_path}'.")  # Afficher un message confirmant l'enregistrement
